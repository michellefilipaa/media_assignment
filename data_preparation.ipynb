{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import string\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from transformers import pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/all_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to clean-up texts\n",
    "def clean_text(x):\n",
    "\n",
    "    # remove punctuation\n",
    "    x = x.translate(str.maketrans(' ', ' ', string.punctuation))\n",
    "\n",
    "    # lowercase\n",
    "    x = x.lower()\n",
    "\n",
    "    # remove — and ’\n",
    "    x = re.sub(\"—\", \" \", x)\n",
    "    x = re.sub(\"’\", \" \", x)\n",
    "    x = re.sub(\"–\", \" \", x)\n",
    "    x = re.sub(\"…\", \" \", x)\n",
    "    x = re.sub(\"“\", \" \", x)\n",
    "    x = re.sub(\"”\", \" \", x)\n",
    "    #x = re.sub(\"\\\\x\", \" \", x)\n",
    "\n",
    "    # strip excessive whitespaces\n",
    "    x = x.strip()\n",
    "\n",
    "    # remove stopwords\n",
    "    # x = [token for token in x if not token in stop_words]\n",
    "\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_cleaned = df['description'].apply(clean_text)\n",
    "synopsis_small_cleaned = df['synopsis_small'].apply(clean_text)\n",
    "print(description_cleaned.equals(synopsis_small_cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['synopsis'] = np.where(df['synopsis_large'] != 'No data found', df['synopsis_large'],\n",
    "                                   np.where(df['synopsis_medium'] != 'No data found', df['synopsis_medium'],\n",
    "                                            df['synopsis_small']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['synopsis_large', 'synopsis_medium'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Child Appropriateness Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section prepares the dataset for the metrics that are necessary for the Child Appropriateness Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiment_analysis method returns the label and the confidence/accuracy of the classification.\n",
    "    If the clasification is positive, the method will simply return the accuracy score. If it is negative, it will \n",
    "    return the negative of the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = pipeline(\"sentiment-analysis\", model=\"siebert/sentiment-roberta-large-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_sentiment(text):\n",
    "    output = sentiment_analysis(text)\n",
    "    score = round(output[0]['score'], 4) if output else None #round the sentiment score to 4 decimal places\n",
    "\n",
    "    if output[0]['label'] == 'NEGATIVE':\n",
    "        return -score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['synopsis'].apply(analyse_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating_description_score'] = df['rating_description'].apply(analyse_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specific content within the synopsis that could be potentially inappropriate for children, such as violence, sexual content, drug references, profanity, etc. is searched for and assessed through a term frequency matrix, indicating the portion of the unsuitable terms present within the description. The same terms will be used for all age groups but the final weighting will be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def remove_stopwords_and_lemmatize(x):\n",
    "    tokens = word_tokenize(x)\n",
    "    \n",
    "    tokens = [lemmatizer.lemmatize(token.lower()) for token in tokens if token.lower() not in stop_words]\n",
    "    \n",
    "    result = []\n",
    "    for i, token in enumerate(tokens):\n",
    "        if i > 0 and all(char in string.punctuation for char in token):\n",
    "            result[-1] += token\n",
    "        else:\n",
    "            result.append(token)\n",
    "    \n",
    "    return ' '.join(result)\n",
    "\n",
    "df['synopsis_nostopwords'] = df['synopsis'].apply(remove_stopwords_and_lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_terms = ['blood', 'gore', 'kill', 'murder', 'torture', 'assualt, weapon', 'war']\n",
    "sexual_terms = ['sex', 'pornography', 'nude', 'erotic']\n",
    "drug_terms = ['cocaine', 'heroin', 'weed', 'alcohol', 'drug']\n",
    "scary_terms = ['horror', 'terror', 'panic', 'frighten', 'violence']\n",
    "mature_terms = ['suicide', 'depression', 'mentall illness', 'abuse', 'death']\n",
    "language_terms = ['language', 'swear', 'rude']\n",
    "unsuitable_terms = violence_terms + sexual_terms + drug_terms + scary_terms + mature_terms + language_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    This method counts each unsuitable word found in a sentence and returns the negated fraction of the unsuitable words over\n",
    "    the total number of words in the sentence.\n",
    "\"\"\"\n",
    "def vectorize_row(text, unsuitable_terms):\n",
    "    words = text.split()  \n",
    "    unsuitable_terms_count = 0\n",
    "    \n",
    "    for word in words:\n",
    "        if word.lower() in unsuitable_terms:\n",
    "            unsuitable_terms_count += 1\n",
    "    \n",
    "    total_terms = len(words)\n",
    "    \n",
    "    return -(unsuitable_terms_count / total_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['unsuitable_ratio'] = df.apply(lambda row: vectorize_row(row['synopsis_nostopwords'], unsuitable_terms), axis=1)\n",
    "df['unsuitable_ratio2'] = df.apply(lambda row: vectorize_row(row['rating_description'], unsuitable_terms), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age Rating per Movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the age rating has no numeric value. Now, a score will be assigned based on the rating. The numerical value represents the proportion of children aged between 4 and 17 that can safely view the content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_mapping = {'U': 1, 'PG': 0.71, '12': 0.57, '12A': 0.57, '15':0.21, '18': 0.0}\n",
    "def age_rating_weighting(rating):\n",
    "    return rating_mapping(rating, 0.0)\n",
    "\n",
    "df['age_rating_numeric'] = df['age_rating'].map(rating_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Child Appropriateness Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$sentiment$ is the Sentiment Analysis score for the synopsis <br>\n",
    "$freq1$ is the proportion of the synopsis that contains any of the unsuitable terms <br>\n",
    "$freq2$ is the proportion of the age description that contains any unsuitable terms <br>\n",
    "$rating$ is the score for the Age Rating <br>\n",
    "$rating\\_desc\\_score$ is the Sentiment Anlaysis score for the rating description <br>\n",
    "\n",
    "$s$: is the weight for the Sentiment Analysis score <br>\n",
    "$t1$: is the weight for the Term Frequency score for the synopses <br>\n",
    "$t2$: is the weight for the Term Frequency score for the age description<br>\n",
    "$r1$: is the weight for the Age Rating score <br>\n",
    "$r2$: is the weight for the Age Rating Description score <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def child_appropriateness_score(sentiment, freq1, freq2, rating, rating_desc_score, s, t1, t2, r1, r2):\n",
    "    return s*sentiment + t1*freq1 + t2*freq2 + r1*rating + r2*rating_desc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the weighting for each age group\n",
    "w48 = [0.2, 0.15, 0.15, 0.3, 0.2]\n",
    "w911 = [0.20, 0.125, 0.125, 0.30, 0.25]\n",
    "w1214 = [0.20, 0.10, 0.10, 0.25, 0.35]\n",
    "w1517 = [0.15, 0.075, 0.075, 0.20, 0.50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cas48'] = df.apply(\n",
    "    lambda row: child_appropriateness_score(row['sentiment'], row['unsuitable_ratio'], row['unsuitable_ratio2'],row['age_rating_numeric'], \n",
    "                                            row['rating_description_score'], w48[0], w48[1], w48[2], w48[3], w48[4]), axis=1)\n",
    "\n",
    "df['cas911'] = df.apply(\n",
    "    lambda row: child_appropriateness_score(row['sentiment'], row['unsuitable_ratio'], row['unsuitable_ratio2'],row['age_rating_numeric'],\n",
    "                                            row['rating_description_score'], w911[0], w911[1], w911[2], w911[3], w911[4]), axis=1)\n",
    "\n",
    "df['cas1214'] = df.apply(\n",
    "    lambda row: child_appropriateness_score(row['sentiment'], row['unsuitable_ratio'], row['unsuitable_ratio2'], row['age_rating_numeric'],\n",
    "                                            row['rating_description_score'], w1214[0], w1214[1], w1214[2], w1214[3], w1214[4]), axis=1)\n",
    "\n",
    "df['cas1517'] = df.apply(\n",
    "    lambda row: child_appropriateness_score(row['sentiment'], row['unsuitable_ratio'], row['unsuitable_ratio2'],row['age_rating_numeric'],\n",
    "                                           row['rating_description_score'], w1517[0], w1517[1], w1517[2], w1517[3], w1517[4]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommendations for 4-6\n",
    "recommendations4_8 = df[['category', 'title', 'tags', 'age_rating', 'image','synopsis_small', 'cas48']].sort_values(by='cas48', ascending=False)\n",
    "filtered4_8 = recommendations4_8[recommendations4_8['cas48'] >= 0.6]\n",
    "\n",
    "# recommendations for 9-11 and under\n",
    "recommendations9_11 = df[['category', 'title', 'tags', 'age_rating', 'image','synopsis_small', 'cas911']].sort_values(by='cas911', ascending=False)\n",
    "filtered9_11 = recommendations9_11[recommendations9_11['cas911'] >= 0.6]\n",
    "\n",
    "# recommendations for 12-14\n",
    "recommendations12_14 = df[['category', 'title', 'tags', 'age_rating', 'image','synopsis_small', 'cas1214']].sort_values(by='cas1214', ascending=False)\n",
    "filtered12_14 = recommendations12_14[recommendations12_14['cas1214'] >= 0.6]\n",
    "\n",
    "# recommendations for 15-17\n",
    "recommendations15_17 = df[['category', 'title', 'tags', 'age_rating', 'image','synopsis_small', 'cas1517']].sort_values(by='cas1517', ascending=False)\n",
    "filtered15_17 = recommendations15_17[recommendations15_17['cas1517'] >= 0.6]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
